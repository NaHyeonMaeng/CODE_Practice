{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmUDhkUeiiAdVf3JGanmhf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaHyeonMaeng/CODE_Practice/blob/main/BERT_%EC%9E%84%EB%B2%A0%EB%94%A9_%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0_%EB%AA%A8%EB%93%A0_%EC%9D%B8%EC%BD%94%EB%8D%94_%EB%A0%88%EC%9D%B4%EC%96%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 추출"
      ],
      "metadata": {
        "id": "dgKSKYg1a4r4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CAw3WYIa1qT",
        "outputId": "1338b2fb-872e-4c8e-be0e-8ea5f22ce91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==2.1.1 in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (1.23.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (1.28.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (4.66.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (2023.6.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (0.1.99)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==2.1.1) (0.0.53)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.25 in /usr/local/lib/python3.10/dist-packages (from boto3->transformers==2.1.1) (1.31.25)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->transformers==2.1.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->transformers==2.1.1) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.1.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.1.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.1.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==2.1.1) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==2.1.1) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==2.1.1) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==2.1.1) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.25->boto3->transformers==2.1.1) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==2.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 모듈 가져오기\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "fyErUFKabDCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#사전 학습된 BERT 모델 및 토크나이저 다운로드\n",
        "#output_hidden_states = True로 설정 -> 모든 인코더 레이어에서 임베딩을 얻는 데 필요함\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgJ9sj3HbFTo",
        "outputId": "d0662764-9e06-4936-e767-e8f05782ed75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 1036014.62B/s]\n",
            "100%|██████████| 440473133/440473133 [00:12<00:00, 34412603.99B/s]\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 1270526.25B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 전처리"
      ],
      "metadata": {
        "id": "w2TuxAyibi6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I love Paris'\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]']"
      ],
      "metadata": {
        "id": "YM53UVyabil-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PAD 토큰 추가, 어텐션 마스크 정의\n",
        "tokens = tokens + ['[PAD]'] + ['[PAD]']\n",
        "attention_mask = [1 if i!= '[PAD]' else 0 for i in tokens]"
      ],
      "metadata": {
        "id": "TJ50NrPBbmUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰을 토큰ID로 변경\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "metadata": {
        "id": "RgCRD-vYbro4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서로 변환\n",
        "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "attention_mask = torch.tensor(attention_mask).unsqueeze(0)"
      ],
      "metadata": {
        "id": "NI7kIiRmbvhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 가져오기"
      ],
      "metadata": {
        "id": "XG6GLBKKbzUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last_hidden_state: 최종 인코더 계층에서만 얻은 모든 토큰의 표현을 가짐\n",
        "#pooler_output: 최종 인코더 계층의 [CLS] 토큰 표현을 나타내며 선형 및 tanh 활성화 함수에 의해 계산됨\n",
        "#hidden_states: 모든 인코더 계층에서 얻은 모든 토큰의 표현을 포함\n",
        "last_hidden_state, pooler_output, hidden_states = model(token_ids, attention_mask = attention_mask)"
      ],
      "metadata": {
        "id": "u7bdw3aAbyAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[batch_size, sequence_length, hidden_size]\n",
        "last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXYJOlwScQX7",
        "outputId": "c9b14c29-83ca-4b7d-8e36-0b7f1ecaaf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[batch_size, hidden_size]\n",
        "pooler_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAAqqFnYcxJD",
        "outputId": "7663a122-dde5-43b5-da69-fdb8fa6f5e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 임베딩 레이어 h0에서 최종 인코더 레이어 h12까지 모든 인코더 레이어의 표현을 포함하는 13개의 값을 포함하는 튜플\n",
        "len(hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt5ERis_dAm1",
        "outputId": "b187ff20-b73c-472b-ea89-3ab4336d290e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 임베딩 레이어 h0에서 얻은 모든 토큰의 표현 벡터를 가짐\n",
        "#[batch_size, sequence_length, hidden_size]\n",
        "hidden_states[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHt1a1VhdOqj",
        "outputId": "ec1c9509-6f88-4046-dd91-6143ee76c73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}